{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreProcessing.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVW2aDTAVMDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import re\n",
        "import itertools\n",
        "from autocorrect import Speller"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-EB5nwKbY6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# words which contains apostroph and also has negative meaning\n",
        "\n",
        "contractions = {\n",
        "\"ain't\": \"are not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\",\n",
        "\"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\", \"isn't\": \"is not\", \"mayn't\": \"may not\", \"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
        "\"needn't\": \"need not\", \"needn't've\": \"need not have\", \"oughtn't\": \"ought not\", \n",
        "\"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \n",
        "\"shan't've\": \"shall not have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
        "\"wasn't\": \"was not\", \"weren't\": \"were not\", \"won't\": \"will not\",\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
        "\n",
        "\"aint\": \"are not\", \"arent\": \"are not\", \"cant\": \"cannot\", \"cant've\": \"cannot have\",\n",
        "\"couldnt\": \"could not\", \"couldnt've\": \"could not have\", \"didnt\": \"did not\", \"doesnt\": \"does not\",\n",
        "\"dont\": \"do not\", \"hadnt\": \"had not\", \"hadnt've\": \"had not have\", \"hasnt\": \"has not\",\n",
        "\"havent\": \"have not\", \"isnt\": \"is not\", \"maynt\": \"may not\", \"mightnt\": \"might not\",\n",
        "\"mightnt've\": \"might not have\", \"mustnt\": \"must not\", \"mustnt've\": \"must not have\", \n",
        "\"neednt\": \"need not\", \"neednt've\": \"need not have\", \"oughtnt\": \"ought not\", \n",
        "\"oughtnt've\": \"ought not have\", \"shant\": \"shall not\", \"shant\": \"shall not\", \n",
        "\"shant've\": \"shall not have\", \"shouldnt\": \"should not\", \"shouldnt've\": \"should not have\",\n",
        "\"wasnt\": \"was not\", \"werent\": \"were not\", \"wont\": \"will not\",\"wont've\": \"will not have\",\n",
        "\"would've\": \"would have\", \"wouldnt\": \"would not\", \"wouldnt've\": \"would not have\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGpuHfzWrR8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "# 'not' & 'no' indicate that certain sentence has negative meaning.\n",
        "stop_words.discard('not')\n",
        "stop_words.discard('no')\n",
        "\n",
        "# add some stopwords\n",
        "stop_words.add('yet')\n",
        "stop_words.add('mine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrunQql0l0_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextCleaner():\n",
        "\n",
        "    def __stim_html_tags(self, text:str):\n",
        "        clean = re.compile('<.*?>')\n",
        "        clean = re.sub(clean, '', text)\n",
        "        clean = re.sub('[\\n\\t]', '', clean)\n",
        "\n",
        "        return clean.lower() # convert all letters to lowrcase version\n",
        "\n",
        "    def __remove_numbers(self, text:str):\n",
        "        return re.sub(r'\\d+', '', text)\n",
        "\n",
        "    def __remove_punctuation(self, text:str):\n",
        "        punctuations = '!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~' # don't remove \"  '  \" char.\n",
        "        no_punc_chars = [char for char in text if char not in punctuations]\n",
        "\n",
        "        return ''.join(no_punc_chars)\n",
        "\n",
        "    def __lemmatizing_words(self, text:str):\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        \n",
        "        # stemming: is the process of eliminating affixes (suffixed, prefixes, infixes, circumfixes) from a word\n",
        "        # books -> book, running->run\n",
        "        text = [lemmatizer.lemmatize(token, \"v\") for token in text.split(' ')]\n",
        "        # lemmatizing: like stemming, the diference is it captures canonical forms based on a word's lemma.\n",
        "        # best -> good, worst -> bad\n",
        "        text = [lemmatizer.lemmatize(token, \"a\") for token in text]\n",
        "\n",
        "        return text\n",
        "\n",
        "    def __remove_stopwords(self, text:list):\n",
        "        # to remove words with apostroph which contains negative meaning\n",
        "        words = []\n",
        "        for word in text:\n",
        "            if word in contractions.keys():\n",
        "                words.extend(contractions[word].split())\n",
        "            else:\n",
        "                words.append(word)\n",
        "\n",
        "        words = [word for word in words if word not in stop_words]\n",
        "        \n",
        "        return ' '.join(words)\n",
        "\n",
        "    # use for give input. training data is already clear.\n",
        "    def standardize_words(self, text:str):\n",
        "        # converting letters of a word at most 2 times if it repeats at least one time.\n",
        "        text = ''.join(''.join(word)[:2] for _, word in itertools.groupby(text))\n",
        "        # then correct speeling of the word\n",
        "        text = Speller(lang='en')(text)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def clean_text(self, text:str):\n",
        "        text = self.__stim_html_tags(text)     # step 1: removing html tags and convert text to lowercase letters\n",
        "        text = self.__remove_numbers(text)     # step 2: removing numbers from text\n",
        "        text = self.__remove_punctuation(text) # step 3: removing punctuations from text\n",
        "        text = self.__lemmatizing_words(text)  # step 4: lemmatizing and stemming words in text\n",
        "        text = self.__remove_stopwords(text)   # step 5: removing stopwords\n",
        "\n",
        "        return text"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}